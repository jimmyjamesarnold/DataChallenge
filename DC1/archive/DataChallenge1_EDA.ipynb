{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv('employee_retention_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore data\n",
    "print('shape: ',df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seems like we could engineer a feature to see time at company. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define quitters\n",
    "df.loc[:, 'quit'] = 1\n",
    "df.loc[df['quit_date'].isnull(), 'quit'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dates columns to datetime\n",
    "df['join_date'] = pd.to_datetime(df['join_date'])\n",
    "df['quit_date'] = pd.to_datetime(df['quit_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engineer 'time at co' feature - calc timedelta and convert to float\n",
    "def f(row):\n",
    "    if row['quit'] == 1:\n",
    "        val = ((row['quit_date'] - row['join_date'])/ np.timedelta64(1, 'Y'))\n",
    "    elif row['quit'] == 0:\n",
    "        val = ((pd.to_datetime('2015-12-13') - row['join_date'])/ np.timedelta64(1, 'Y'))\n",
    "    return val\n",
    "\n",
    "df['time_at_Co'] = df.apply(f, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.seniority.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.salary.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.time_at_Co.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at time at company\n",
    "sns.set(context = 'poster', style = 'white')\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.violinplot(x = 'dept', y = 'time_at_Co',  hue = 'quit', data = df, split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like a lot of people leave at 12 months and 24 months. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at salaries\n",
    "#plt.figure(figsize=(20,10))\n",
    "#sns.violinplot(x = 'dept', y = 'salary',  hue = 'quit', data = df, split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# might play some part, but not as stark as time_at_Co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at experience\n",
    "#plt.figure(figsize=(20,10))\n",
    "#sns.violinplot(x = 'dept', y = 'seniority',  hue = 'quit', data = df, split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like some outliers in marketing and engineering\n",
    "# might need to tweak these features to bins instead of continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin seniority into 3 bins = idea being junior, mid, and senior\n",
    "#df['seniority_bin'] = pd.qcut(df.seniority, 3, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks to some slight differences between more experienced individuals and salary, but not at junior level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at salary per experience amoung data scientists\n",
    "#plt.figure(figsize=(20,10))\n",
    "#sns.violinplot(x = 'seniority_bin', y = 'salary',  hue = 'quit', data = df.loc[df['dept'] == 'data_science',] , split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at salary per experience amoung data scientists\n",
    "#plt.figure(figsize=(20,10))\n",
    "#sns.violinplot(x = 'seniority_bin', y = 'time_at_Co',  hue = 'quit', data = df.loc[df['dept'] == 'data_science',] , split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regardless of experience, bulk of quitters leave at 1 year, with spikes at 2 and 3 years\n",
    "# my intutition is that this is enough time for individuals to feel the company out for fit, role, team, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make this model better, need to engineer features to distinguish employees who stay greater than 1 year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engineer feature to label salary with respect to peers\n",
    "# calculate median salary per dept per seniority -\n",
    "median_salary = df.groupby(['dept', 'seniority'])[['salary']].apply(np.median)\n",
    "median_salary.name = 'median'\n",
    "df = df.join(median_salary, on=['dept', 'seniority'])\n",
    "\n",
    "# calculate the difference in average salary of individual to median\n",
    "df['salary_diff'] = df['salary'] - df['median']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at salary_diff per dept\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.violinplot(x = 'dept', y = 'salary_diff',  hue = 'quit', data = df , split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this seems to indicate that relative salary isn't a major factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at salary_diff per company_id\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.violinplot(x = 'company_id', y = 'salary_diff',  hue = 'quit', data = df , split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# company 11 looks weird. \n",
    "# 1 and 2 definitely pay the best\n",
    "# not a visible difference between quitters and stayers with respect to salary diff, except at 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop employee id, not important\n",
    "df.drop(['employee_id', 'join_date', 'quit_date', 'median', 'salary_diff'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encode dept\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['dept'] = le.fit_transform(df['dept'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure there's no missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df['quit'].values\n",
    "X = df.drop(['quit'],axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "# Create a based model\n",
    "lr = LogisticRegression()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = lr, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 2)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "lr = LogisticRegression(C=0.01)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "# Print the prediction accuracy\n",
    "print (metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC(dual=False, random_state=42)\n",
    "\n",
    "param_grid = [{'C': [0.1, 1, 10, 100, 1000]}]\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "# fit best model\n",
    "clf = LinearSVC(C = 0.1, random_state = 42, dual=False)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "# Print the prediction accuracy\n",
    "print (metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "param_grid = {\"n_estimators\": [10, 20, 50, 100],\n",
    "              \"max_depth\": [2, 3, 4, None],\n",
    "              \"max_features\": [1, 2, 3, 'auto'],\n",
    "              \"min_samples_split\": [2, 5, 10, 20],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(rf, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "# fit best model\n",
    "rf = RandomForestClassifier(n_estimators = 50,\n",
    "                            max_depth = None,\n",
    "                            max_features = 3,\n",
    "                            min_samples_split = 20,\n",
    "                            bootstrap = False,\n",
    "                            criterion = 'entropy',\n",
    "                            random_state = 42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "# Print the prediction accuracy\n",
    "print (metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional\n",
    "!pip install pdpbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdpbox import pdp, get_dataset, info_plots\n",
    "\n",
    "# Create the data that we will plot\n",
    "pdp_goals = pdp.pdp_isolate(model=rf, dataset=X_test, model_features=X_test.columns.tolist(), feature='time_at_Co')\n",
    "\n",
    "# plot it\n",
    "pdp.pdp_plot(pdp_goals, 'time_at_Co')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data that we will plot\n",
    "pdp_goals = pdp.pdp_isolate(model=rf, dataset=X_test, model_features=X_test.columns.tolist(), feature='salary')\n",
    "\n",
    "# plot it\n",
    "pdp.pdp_plot(pdp_goals, 'salary_diff')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_plot = ['time_at_Co', 'salary_diff']\n",
    "inter1  =  pdp.pdp_interact(model=rf, dataset=X_test, model_features=X_test.columns.tolist(), features=features_to_plot)\n",
    "\n",
    "pdp.pdp_interact_plot(pdp_interact_out=inter1, feature_names=features_to_plot, plot_type='contour')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional\n",
    "!pip install eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature importances using permutation \n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(rf, random_state=42).fit(X_test, y_test)\n",
    "eli5.show_weights(perm, feature_names = X_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional\n",
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize feature importances using SHAP\n",
    "import shap  # package used to calculate Shap values\n",
    "\n",
    "# Create object that can calculate shap values\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "\n",
    "# calculate shap values. This is what we will plot.\n",
    "# Calculate shap_values for all of val_X rather than a single row, to have more data for plot.\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Make plot. Index of [1] is explained in text below.\n",
    "shap.summary_plot(shap_values[1], X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intrepetation:\n",
    "# very little time at company negatively impacts quitting prediction, but medium values positively influence it. \n",
    "# spending a long time at the company doesn't much matter\n",
    "# high salary scores negatively predict quitting\n",
    "# seniority doesn't have much impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate PDP comparing time at Co vs salary\n",
    "# make plot.\n",
    "shap.dependence_plot('salary', shap_values[1], X_test, interaction_index=\"time_at_Co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vice versa\n",
    "shap.dependence_plot('time_at_Co', shap_values[1], X_test, interaction_index=\"salary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best predictor seems to be time at the company. \n",
    "# would be itnerested in obtaining a 'satisfaction score' from employees. My bet is something is ticking them off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
